"use client";

import { useState, useRef, useEffect } from "react";

export default function AudioPage() {
  const [isRecording, setIsRecording] = useState(false);
  const [audioChunks, setAudioChunks] = useState<Int16Array[]>([]);
  const [status, setStatus] = useState("å¾…æ©Ÿä¸­");

  const audioContextRef = useRef<AudioContext | null>(null);
  const workletNodeRef = useRef<AudioWorkletNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const audioBufferRef = useRef<Int16Array[]>([]);

  useEffect(() => {
    return () => {
      // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
    };
  }, []);

  const startRecording = async () => {
    try {
      setStatus("ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¦æ±‚ä¸­...");

      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
          sampleRate: 48000,
        },
      });
      streamRef.current = stream;

      const audioContext = new AudioContext({ sampleRate: 48000 });
      audioContextRef.current = audioContext;

      setStatus("AudioWorkletã‚’èª­ã¿è¾¼ã¿ä¸­...");

      await audioContext.audioWorklet.addModule("/audio-processer.js");

      const source = audioContext.createMediaStreamSource(stream);
      const workletNode = new AudioWorkletNode(
        audioContext,
        "realtime-audio-processor",
      );
      workletNodeRef.current = workletNode;

      // AudioWorkletã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡
      workletNode.port.onmessage = (event) => {
        if (event.data.type === "audioData") {
          audioBufferRef.current.push(event.data.pcm16);
          setStatus(`éŒ²éŸ³ä¸­... (RMS: ${event.data.rms.toFixed(4)})`);
        } else if (event.data.type === "silence") {
          setStatus("éŒ²éŸ³ä¸­... (ç„¡éŸ³)");
        }
      };

      source.connect(workletNode);
      workletNode.connect(audioContext.destination);

      // éŒ²éŸ³é–‹å§‹ã‚’é€šçŸ¥
      workletNode.port.postMessage({ type: "setRecording", value: true });

      setIsRecording(true);
      setStatus("éŒ²éŸ³ä¸­...");
      audioBufferRef.current = [];
    } catch (error) {
      console.error("éŒ²éŸ³ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ:", error);
      setStatus(
        `ã‚¨ãƒ©ãƒ¼: ${error instanceof Error ? error.message : "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼"}`,
      );
    }
  };

  const stopRecording = () => {
    if (workletNodeRef.current) {
      // éŒ²éŸ³åœæ­¢ã‚’é€šçŸ¥
      workletNodeRef.current.port.postMessage({
        type: "setRecording",
        value: false,
      });
    }

    if (streamRef.current) {
      streamRef.current.getTracks().forEach((track) => track.stop());
      streamRef.current = null;
    }

    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    // éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    setAudioChunks([...audioBufferRef.current]);
    setIsRecording(false);
    setStatus(`éŒ²éŸ³åœæ­¢ (${audioBufferRef.current.length}ãƒãƒ£ãƒ³ã‚¯ä¿å­˜)`);
  };

  const playRecording = () => {
    if (audioChunks.length === 0) {
      setStatus("å†ç”Ÿã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“");
      return;
    }

    setStatus("å†ç”Ÿä¸­...");

    // ã™ã¹ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆ
    const totalLength = audioChunks.reduce(
      (sum, chunk) => sum + chunk.length,
      0,
    );
    const mergedBuffer = new Int16Array(totalLength);
    let offset = 0;

    for (const chunk of audioChunks) {
      mergedBuffer.set(chunk, offset);
      offset += chunk.length;
    }

    // Int16Arrayã‚’Float32Arrayã«å¤‰æ› (AudioBufferã¯Float32ã‚’ä½¿ç”¨)
    const floatBuffer = new Float32Array(mergedBuffer.length);
    for (let i = 0; i < mergedBuffer.length; i++) {
      floatBuffer[i] =
        mergedBuffer[i] / (mergedBuffer[i] < 0 ? 0x8000 : 0x7fff);
    }

    // AudioContextã§å†ç”Ÿ
    const playContext = new AudioContext({ sampleRate: 24000 }); // éŒ²éŸ³æ™‚ã«24kHzã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹
    const audioBuffer = playContext.createBuffer(1, floatBuffer.length, 24000);
    audioBuffer.copyToChannel(floatBuffer, 0);

    const source = playContext.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(playContext.destination);

    source.onended = () => {
      setStatus("å†ç”Ÿå®Œäº†");
      playContext.close();
    };

    source.start();
  };

  return (
    <div className="min-h-screen flex items-center justify-center bg-gradient-to-br from-gray-50 to-gray-100 dark:from-gray-900 dark:to-gray-800">
      <div className="max-w-md w-full mx-auto p-8 bg-white dark:bg-gray-800 rounded-2xl shadow-xl">
        <h1 className="text-3xl font-bold text-center mb-8 text-gray-800 dark:text-gray-100">
          éŸ³å£°éŒ²éŸ³ãƒ»å†ç”Ÿ
        </h1>

        <div className="mb-8 p-4 bg-gray-100 dark:bg-gray-700 rounded-lg">
          <p className="text-sm text-gray-600 dark:text-gray-300 mb-1">
            ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:
          </p>
          <p className="font-mono text-sm text-gray-800 dark:text-gray-100">
            {status}
          </p>
          {audioChunks.length > 0 && (
            <p className="text-sm text-gray-600 dark:text-gray-300 mt-2">
              éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿: {audioChunks.length} ãƒãƒ£ãƒ³ã‚¯
            </p>
          )}
        </div>

        <div className="space-y-4">
          <button
            onClick={startRecording}
            disabled={isRecording}
            className={`w-full py-4 px-6 rounded-lg font-semibold text-white transition-all duration-200 ${
              isRecording
                ? "bg-gray-400 cursor-not-allowed"
                : "bg-red-500 hover:bg-red-600 active:scale-95 shadow-lg hover:shadow-xl"
            }`}
          >
            ğŸ¤ éŒ²éŸ³
          </button>

          <button
            onClick={stopRecording}
            disabled={!isRecording}
            className={`w-full py-4 px-6 rounded-lg font-semibold text-white transition-all duration-200 ${
              !isRecording
                ? "bg-gray-400 cursor-not-allowed"
                : "bg-blue-500 hover:bg-blue-600 active:scale-95 shadow-lg hover:shadow-xl"
            }`}
          >
            â¹ åœæ­¢
          </button>

          <button
            onClick={playRecording}
            disabled={isRecording || audioChunks.length === 0}
            className={`w-full py-4 px-6 rounded-lg font-semibold text-white transition-all duration-200 ${
              isRecording || audioChunks.length === 0
                ? "bg-gray-400 cursor-not-allowed"
                : "bg-green-500 hover:bg-green-600 active:scale-95 shadow-lg hover:shadow-xl"
            }`}
          >
            â–¶ï¸ å†ç”Ÿ
          </button>
        </div>

        <div className="mt-8 p-4 bg-blue-50 dark:bg-blue-900/20 rounded-lg border border-blue-200 dark:border-blue-800">
          <p className="text-xs text-gray-600 dark:text-gray-300">
            <strong>ä½¿ã„æ–¹:</strong>
            <br />
            1. ã€ŒéŒ²éŸ³ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯
            <br />
            2. éŸ³å£°ã‚’å…¥åŠ›
            <br />
            3. ã€Œåœæ­¢ã€ãƒœã‚¿ãƒ³ã§éŒ²éŸ³ã‚’çµ‚äº†
            <br />
            4. ã€Œå†ç”Ÿã€ãƒœã‚¿ãƒ³ã§éŒ²éŸ³ã—ãŸéŸ³å£°ã‚’ç¢ºèª
          </p>
        </div>
      </div>
    </div>
  );
}
